model: 
  shape: hybrid
  n_windows: 8
  window_size: null
  distribution: Multi-Bernoulli
  codebook_size: 25
  num_classes: 7
  encoder:
    layer0:
      size: 10005
      dropout: 0
      normalize: true
      activation: ReLU
    layer1: 
      size: 1024
      dropout: null
      normalize: true
      activation: ReLU
    layer2: 
      size: 256
      dropout: null
      normalize: true
      activation: Tanh
    layer3: 
      size: 64
  decoder: 
    layer0:
      size: 64
      dropout: 0
      normalize: true
      activation: ReLU
    layer1:
      size: 256
      dropout: 0
      normalize: true
      activation: ReLU
    layer2:
      size: 1024
      dropout: 0
      normalize: true
      activation: ReLU
    layer3:
      size: 10005

hyperparams:
  epochs: 3000
  batch_size: 128
  lr: 0.0001
  beta: 1
  weight_decay: 0
  scheduler: 
    method: plateau
    factor: 0.1
    patience: 5
    threshold: 0.0001
    mode: rel
